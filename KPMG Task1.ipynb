{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of worksheets is 5\n",
      "Worksheet name(s): ['Title Sheet', 'Transactions', 'NewCustomerList', 'CustomerDemographic', 'CustomerAddress']\n"
     ]
    }
   ],
   "source": [
    "# Lets find out what worksheets are in provided excel file\n",
    "\n",
    "import xlrd\n",
    "book = xlrd.open_workbook(\"KPMG.xlsx\")\n",
    "print(\"The number of worksheets is {0}\".format(book.nsheets))\n",
    "print(\"Worksheet name(s): {0}\".format(book.sheet_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the xlsx file each of 3 required sheets into separate variables\n",
    "\n",
    "transactions = pd.read_excel(\"KPMG.xlsx\", 'Transactions', header = 1)\n",
    "customerdemo = pd.read_excel(\"KPMG.xlsx\", 'CustomerDemographic', header = 1)\n",
    "customeradd = pd.read_excel(\"KPMG.xlsx\", 'CustomerAddress', header = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_1. Lets start looking inside transactions data. By describe() and summing NaN we'll see missing info in each columns if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transactions quantity 20000 \n",
      "\n",
      "       transaction_id   product_id   customer_id  online_order    list_price  \\\n",
      "count    20000.000000  20000.00000  20000.000000  19640.000000  20000.000000   \n",
      "mean     10000.500000     45.36465   1738.246050      0.500458   1107.829449   \n",
      "std       5773.647028     30.75359   1011.951046      0.500013    582.825242   \n",
      "min          1.000000      0.00000      1.000000      0.000000     12.010000   \n",
      "25%       5000.750000     18.00000    857.750000      0.000000    575.270000   \n",
      "50%      10000.500000     44.00000   1736.000000      1.000000   1163.890000   \n",
      "75%      15000.250000     72.00000   2613.000000      1.000000   1635.300000   \n",
      "max      20000.000000    100.00000   5034.000000      1.000000   2091.470000   \n",
      "\n",
      "       standard_cost  product_first_sold_date  \n",
      "count   19803.000000             19803.000000  \n",
      "mean      556.046951             38199.776549  \n",
      "std       405.955660              2875.201110  \n",
      "min         7.210000             33259.000000  \n",
      "25%       215.140000             35667.000000  \n",
      "50%       507.580000             38216.000000  \n",
      "75%       795.100000             40672.000000  \n",
      "max      1759.850000             42710.000000  \n",
      "\n",
      "    transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
      "0               1           2         2950       2017-02-25           0.0   \n",
      "1               2           3         3120       2017-05-21           1.0   \n",
      "2               3          37          402       2017-10-16           0.0   \n",
      "3               4          88         3135       2017-08-31           0.0   \n",
      "4               5          78          787       2017-10-01           1.0   \n",
      "\n",
      "  order_status           brand product_line product_class product_size  \\\n",
      "0     Approved           Solex     Standard        medium       medium   \n",
      "1     Approved   Trek Bicycles     Standard        medium        large   \n",
      "2     Approved      OHM Cycles     Standard           low       medium   \n",
      "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
      "4     Approved  Giant Bicycles     Standard        medium        large   \n",
      "\n",
      "   list_price  standard_cost  product_first_sold_date  \n",
      "0       71.49          53.62                  41245.0  \n",
      "1     2091.47         388.92                  41701.0  \n",
      "2     1793.43         248.82                  36361.0  \n",
      "3     1198.46         381.10                  36145.0  \n",
      "4     1765.30         709.48                  42226.0  \n"
     ]
    }
   ],
   "source": [
    "# See the quantitative summary of transactions\n",
    "print(\"transactions quantity {} \\n\".format(len(transactions)))\n",
    "print(transactions.describe())\n",
    "print('\\n',transactions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_2. Quantitative data about prices seem reasonable. Let check completeness of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_id               0\n",
      "product_id                   0\n",
      "customer_id                  0\n",
      "transaction_date             0\n",
      "online_order               360\n",
      "order_status                 0\n",
      "brand                      197\n",
      "product_line               197\n",
      "product_class              197\n",
      "product_size               197\n",
      "list_price                   0\n",
      "standard_cost              197\n",
      "product_first_sold_date    197\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check Completeness\n",
    "\n",
    "# Sum nulls whenever True it will sum up and give total missing values\n",
    "print(transactions.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lack info about online_order for 360 transactions, and 197 missing data for brand, product_line etc.\n",
    "    Is this missing data overlap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " quantity of transactions where any info is missing 555 \n",
      "\n",
      "\n",
      "        transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
      "136               137           0          431       2017-09-23           0.0   \n",
      "159               160           0         3300       2017-08-27           0.0   \n",
      "366               367           0         1614       2017-03-10           0.0   \n",
      "406               407           0         2559       2017-06-14           1.0   \n",
      "676               677           0         2609       2017-07-02           0.0   \n",
      "...               ...         ...          ...              ...           ...   \n",
      "19340           19341           0          443       2017-12-26           1.0   \n",
      "19383           19384           0         2407       2017-06-11           0.0   \n",
      "19793           19794           0         2860       2017-01-13           0.0   \n",
      "19859           19860           0         2468       2017-06-24           1.0   \n",
      "19871           19872           0           61       2017-03-17           1.0   \n",
      "\n",
      "      order_status brand product_line product_class product_size  list_price  \\\n",
      "136       Approved   NaN          NaN           NaN          NaN     1942.61   \n",
      "159       Approved   NaN          NaN           NaN          NaN     1656.86   \n",
      "366       Approved   NaN          NaN           NaN          NaN      850.89   \n",
      "406       Approved   NaN          NaN           NaN          NaN      710.59   \n",
      "676       Approved   NaN          NaN           NaN          NaN     1972.01   \n",
      "...            ...   ...          ...           ...          ...         ...   \n",
      "19340     Approved   NaN          NaN           NaN          NaN      744.54   \n",
      "19383     Approved   NaN          NaN           NaN          NaN     1098.18   \n",
      "19793     Approved   NaN          NaN           NaN          NaN      868.56   \n",
      "19859     Approved   NaN          NaN           NaN          NaN     1497.43   \n",
      "19871     Approved   NaN          NaN           NaN          NaN      867.92   \n",
      "\n",
      "       standard_cost  product_first_sold_date  \n",
      "136              NaN                      NaN  \n",
      "159              NaN                      NaN  \n",
      "366              NaN                      NaN  \n",
      "406              NaN                      NaN  \n",
      "676              NaN                      NaN  \n",
      "...              ...                      ...  \n",
      "19340            NaN                      NaN  \n",
      "19383            NaN                      NaN  \n",
      "19793            NaN                      NaN  \n",
      "19859            NaN                      NaN  \n",
      "19871            NaN                      NaN  \n",
      "\n",
      "[197 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#Check Completeness further\n",
    "#combine cases where online_order and brand columns are null\n",
    "print(\"\\n quantity of transactions where any info is missing {} \\n\".format(len(transactions[(transactions.online_order.isnull()) | (transactions.brand.isnull())])))\n",
    "\n",
    "# look into 197 rows of missing data\n",
    "print('\\n',transactions[(transactions.brand.isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first order made on 2017-01-01 00:00:00.  Last order made on 2017-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Check Consistency\n",
    "#Check for first and last transaction date\n",
    "print('first order made on {}. '.format(transactions.transaction_date.min()),'Last order made on {}'.format(transactions.transaction_date.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_3. online_order info just carries info about whether the transaction was done online or in store, i assume considering small amount of missing data, its not so critical for analytical purposes for this case and 360 rows can be filled with either of choices 1 or 0.<br> \n",
    "    Other 197 missing data in 6 columns brand, product_line, product_class, product_size, standard_cost, product_first_sold_date are carrying important information, and other way than just removing these rows i can't suggest. I might assume it could be some kind of service rather than product done both online and in store. Transaction_dates are consistent, all orders are made within 1 year.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete variable in case this lines of code will be run several times\n",
    "#del(transactions_new)\n",
    "\n",
    "#Solve inConsistency\n",
    "# remove rows where brand and other columns are missing\n",
    "transactions_new = transactions.dropna(subset = ['brand'])\n",
    "\n",
    "# fill with 0 rows where online_order is NaN\n",
    "transactions_new.fillna( 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_status  categories:  ['Approved' 'Cancelled']\n",
      "brand  categories:  ['Solex' 'Trek Bicycles' 'OHM Cycles' 'Norco Bicycles' 'Giant Bicycles'\n",
      " 'WeareA2B']\n",
      "product_line  categories:  ['Standard' 'Road' 'Mountain' 'Touring']\n",
      "product_class  categories:  ['medium' 'low' 'high']\n",
      "product_size  categories:  ['medium' 'large' 'small']\n"
     ]
    }
   ],
   "source": [
    "#Check Validity for category columns\n",
    "cat_columns = ['order_status', 'brand', 'product_line', 'product_class', 'product_size']\n",
    "for category in cat_columns:\n",
    "    print(category,' categories: ',transactions_new[category].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    19803\n",
      "Name: transaction_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check Uniqueness\n",
    "#Check keys of database transaction_id\n",
    "print(transactions_new.transaction_id.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many customers made orders out of 4000 (or 4003):  3494  customers\n"
     ]
    }
   ],
   "source": [
    "# Lets see how many customers made transactions\n",
    "tr_custid = np.array(transactions_new.customer_id.sort_values(ascending = True).unique())\n",
    "print('how many customers made orders out of 4000 (or 4003): ',len(tr_custid), ' customers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1_4. Summary according to Data-Quality Dimensions:<br>\n",
    "        Accuracy:<br>\n",
    "            no issues<br>\n",
    "        Completeness:<br>\n",
    "            online_order: missing for 360 transactions; brand, product_line etc: 197 rows of missing data.<br>\n",
    "            197 rows where brand, product_line were missing were deleted; 360 rows of online_order info was filled with 0 <br>\n",
    "        Consistency:<br>\n",
    "            all data is consistent <br>\n",
    "        Currency:<br>\n",
    "            not applicable for current project<br>\n",
    "        Relevancy:<br>\n",
    "            no unnecessary info<br>\n",
    "        Validity:<br>\n",
    "            invalid data in catgorical columns were not found<br>\n",
    "        Uniqueness:<br>\n",
    "            no issues, transaction dataset contains unique transaction_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_id             0\n",
      "product_id                 0\n",
      "customer_id                0\n",
      "transaction_date           0\n",
      "online_order               0\n",
      "order_status               0\n",
      "brand                      0\n",
      "product_line               0\n",
      "product_class              0\n",
      "product_size               0\n",
      "list_price                 0\n",
      "standard_cost              0\n",
      "product_first_sold_date    0\n",
      "dtype: int64\n",
      "\n",
      " Size of new data frame (19803, 13)\n"
     ]
    }
   ],
   "source": [
    "#print quatity of NaN info in any of columns\n",
    "print(transactions_new.isnull().sum())\n",
    "\n",
    "#print new size of dataframe\n",
    "print('\\n Size of new data frame {}'.format(transactions_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2_1. Time to start looking inside CustomerDemographic data. By describe() and summing NaN we'll see missing info in each columns if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer quantity 4000 \n",
      "\n",
      "       customer_id  past_3_years_bike_related_purchases       tenure\n",
      "count  4000.000000                          4000.000000  3913.000000\n",
      "mean   2000.500000                            48.890000    10.657041\n",
      "std    1154.844867                            28.715005     5.660146\n",
      "min       1.000000                             0.000000     1.000000\n",
      "25%    1000.750000                            24.000000     6.000000\n",
      "50%    2000.500000                            48.000000    11.000000\n",
      "75%    3000.250000                            73.000000    15.000000\n",
      "max    4000.000000                            99.000000    22.000000\n",
      "\n",
      " customer_id                              0\n",
      "first_name                               0\n",
      "last_name                              125\n",
      "gender                                  88\n",
      "past_3_years_bike_related_purchases      0\n",
      "DOB                                     87\n",
      "job_title                              506\n",
      "job_industry_category                  656\n",
      "wealth_segment                           0\n",
      "deceased_indicator                       0\n",
      "default                                302\n",
      "owns_car                                 0\n",
      "tenure                                  87\n",
      "dtype: int64\n",
      "\n",
      "    customer_id      first_name  last_name  gender  \\\n",
      "0            1         Laraine  Medendorp  Female   \n",
      "1            2             Eli    Bockman    Male   \n",
      "2            3           Arlin     Dearle    Male   \n",
      "3            4          Talbot        NaN    Male   \n",
      "4            5  Sheila-kathryn     Calton  Female   \n",
      "\n",
      "   past_3_years_bike_related_purchases        DOB               job_title  \\\n",
      "0                                   93 1953-10-12     Executive Secretary   \n",
      "1                                   81 1980-12-16  Administrative Officer   \n",
      "2                                   61 1954-01-20      Recruiting Manager   \n",
      "3                                   33 1961-10-03                     NaN   \n",
      "4                                   56 1977-05-13           Senior Editor   \n",
      "\n",
      "  job_industry_category     wealth_segment deceased_indicator  \\\n",
      "0                Health      Mass Customer                  N   \n",
      "1    Financial Services      Mass Customer                  N   \n",
      "2              Property      Mass Customer                  N   \n",
      "3                    IT      Mass Customer                  N   \n",
      "4                   NaN  Affluent Customer                  N   \n",
      "\n",
      "                                             default owns_car  tenure  \n",
      "0                                                 \"'      Yes    11.0  \n",
      "1                       <script>alert('hi')</script>      Yes    16.0  \n",
      "2                                2018-02-01 00:00:00      Yes    15.0  \n",
      "3  () { _; } >_[$($())] { touch /tmp/blns.shellsh...       No     7.0  \n",
      "4                                                NIL      Yes     8.0  \n"
     ]
    }
   ],
   "source": [
    "# See the summary of customer demographics\n",
    "#Find quantity of customers in database\n",
    "print(\"customer quantity {} \\n\".format(len(customerdemo)))\n",
    "\n",
    "#Compute quantitative summary for numerical columns\n",
    "print(customerdemo.describe())\n",
    "\n",
    "#Caclulate missing data in columns\n",
    "print('\\n',customerdemo.isnull().sum())\n",
    "\n",
    "#overview for data first 5 rows\n",
    "print('\\n',customerdemo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719    1931-10-23\n",
      "1091   1935-08-22\n",
      "3409   1940-09-22\n",
      "2412   1943-08-11\n",
      "657    1944-01-24\n",
      "          ...    \n",
      "421    2002-01-06\n",
      "2857   2002-01-09\n",
      "3434   2002-01-15\n",
      "1887   2002-01-26\n",
      "65     2002-03-11\n",
      "Name: DOB, Length: 3913, dtype: datetime64[ns]\n",
      "1977-07-25 11:08:39.754991296\n",
      "Int64Index([719], dtype='int64')\n",
      "719   1977-07-25 11:08:39.754991296\n",
      "Name: DOB, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "#Check Accuracy\n",
    "#check DOB\n",
    "print(customerdemo.DOB.dropna().sort_values(ascending=True))\n",
    "\n",
    "#solve inAccuracy\n",
    "#find out the mean DOB\n",
    "print(customerdemo.DOB.mean())\n",
    "\n",
    "#find index of impossible BOD\n",
    "print(customerdemo[customerdemo.DOB==customerdemo.DOB.min()].index)\n",
    "\n",
    "#store index\n",
    "old_index=customerdemo[customerdemo.DOB==customerdemo.DOB.min()].index\n",
    "\n",
    "#substitute with mean BOD\n",
    "customerdemo.loc[old_index,'DOB']=customerdemo.DOB.mean()\n",
    "print(customerdemo.loc[old_index,'DOB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doesnt own a car but tenure > 0 : 1939\n"
     ]
    }
   ],
   "source": [
    "#Check Consistency\n",
    "print('Doesnt own a car but tenure > 0 :',len(customerdemo[(customerdemo.owns_car == 'No') & (customerdemo.tenure > 0) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                      \"'\n",
      "1                            <script>alert('hi')</script>\n",
      "2                                     2018-02-01 00:00:00\n",
      "3       () { _; } >_[$($())] { touch /tmp/blns.shellsh...\n",
      "4                                                     NIL\n",
      "                              ...                        \n",
      "3994                                                   á \n",
      "3995                                                 -100\n",
      "3996                                             â¦testâ§\n",
      "3998                               Â¡â¢Â£Â¢âÂ§Â¶â¢ÂªÂºââ \n",
      "3999                                                  0/0\n",
      "Name: default, Length: 3698, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Check Relevancy\n",
    "#check default\n",
    "print(customerdemo.default.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender  categories:  ['Female' 'Male' nan]\n",
      "wealth_segment  categories:  ['Mass Customer' 'Affluent Customer' 'High Net Worth']\n",
      "job_industry_category  categories:  ['Health' 'Financial Services' 'Property' 'IT' nan 'Retail' 'Argiculture'\n",
      " 'Manufacturing' 'Telecommunications' 'Entertainment']\n",
      "deceased_indicator  categories:  ['N' 'Y']\n",
      "owns_car  categories:  ['Yes' 'No']\n"
     ]
    }
   ],
   "source": [
    "#Check Validity for category columns\n",
    "cat_columns = ['gender','wealth_segment', 'job_industry_category', 'deceased_indicator','owns_car']\n",
    "for category in cat_columns:\n",
    "    print(category,' categories: ',customerdemo[category].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female' 'Male' nan]\n"
     ]
    }
   ],
   "source": [
    "#Solve gender categories bu mapping with only 2 gender Female and Male and NaN where U\n",
    "mapping = {'F':'Female','Female':'Female','Femal':'Female','M':'Male', 'Male':'Male', 'U':np.nan}\n",
    "customerdemo['gender']=customerdemo['gender'].map(mapping)\n",
    "print(customerdemo['gender'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [customer_id, first_name, last_name, gender, past_3_years_bike_related_purchases, DOB, job_title, job_industry_category, wealth_segment, deceased_indicator, default, owns_car, tenure]\n",
      "Index: []\n",
      "\n",
      "customer_demo customers with ids:  []\n"
     ]
    }
   ],
   "source": [
    "#Check Uniqueness\n",
    "#Check keys customer_id for database\n",
    "print(customerdemo[customerdemo.customer_id.duplicated()==True])\n",
    "\n",
    "#Check consistency of customer_id it supposed to be from 1 to 4000 total of 4000 counts:\n",
    "x=np.linspace(1,4000,4000).astype('int')\n",
    "customerdemo_list = []\n",
    "custdemoid = np.array(customerdemo.customer_id.sort_values(ascending = True))\n",
    "\n",
    "#iterate over 4000 to find inconsistency in customer_id's\n",
    "for i in x:         \n",
    "    if i not in custdemoid:\n",
    "        customerdemo_list.append(i)\n",
    "        \n",
    "#Print resulting lis, if empty then no inconsistency        \n",
    "print('\\ncustomer_demo customers with ids: ', customerdemo_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2_2. Summary according to Data-Quality Dimensions:<br>\n",
    "        Accuracy:<br>\n",
    "            DOB:contains very old man<br>\n",
    "        Completeness:<br>\n",
    "            DOB, job_title and job_industry_cat columns: missing data, meaning lack of personal info hence less advert possibilities.<br>\n",
    "            last_name: missing, however customer_id is present, not a big issue.<br>\n",
    "        Consistency:<br>\n",
    "            owns_car vs tenure: 3rd row shows customer doesn't posses car however tenure columns shows values. Most probably i dont know what tenure really means in this database, since 1939 rows contain tenure values while not having a car <br>\n",
    "        Currency:<br>\n",
    "            not applicable for current project<br>\n",
    "        Relevancy:<br>\n",
    "            default: contains unnecessary info<br>\n",
    "        Validity:<br>\n",
    "            gender have different categories e.g.: F, Female, Male...<br>\n",
    "        Uniqueness:<br>\n",
    "            no issues, customerdemographics base contains unique customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (4000, 13)\n"
     ]
    }
   ],
   "source": [
    "#Check the shape of final dataframe\n",
    "print('\\n',customerdemo.shape)\n",
    "\n",
    "#store final dataset to new variable\n",
    "\n",
    "customerdemo_new = customerdemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3_1. Finally we check the customer address database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customeraddress quantity 3999 \n",
      "\n",
      "       customer_id     postcode  property_valuation\n",
      "count  3999.000000  3999.000000         3999.000000\n",
      "mean   2003.987997  2985.755939            7.514379\n",
      "std    1154.576912   844.878364            2.824663\n",
      "min       1.000000  2000.000000            1.000000\n",
      "25%    1004.500000  2200.000000            6.000000\n",
      "50%    2004.000000  2768.000000            8.000000\n",
      "75%    3003.500000  3750.000000           10.000000\n",
      "max    4003.000000  4883.000000           12.000000\n",
      "\n",
      " customer_id           0\n",
      "address               0\n",
      "postcode              0\n",
      "state                 0\n",
      "country               0\n",
      "property_valuation    0\n",
      "dtype: int64\n",
      "\n",
      "    customer_id              address  postcode state    country  \\\n",
      "0            1   060 Morning Avenue      2016   NSW  Australia   \n",
      "1            2  6 Meadow Vale Court      2153   NSW  Australia   \n",
      "2            4   0 Holy Cross Court      4211   QLD  Australia   \n",
      "3            5  17979 Del Mar Point      2448   NSW  Australia   \n",
      "4            6     9 Oakridge Court      3216   VIC  Australia   \n",
      "\n",
      "   property_valuation  \n",
      "0                  10  \n",
      "1                  10  \n",
      "2                   9  \n",
      "3                   4  \n",
      "4                   9  \n"
     ]
    }
   ],
   "source": [
    "# See the quantitative summary of customeradd\n",
    "print(\"customeraddress quantity {} \\n\".format(len(customeradd)))\n",
    "print(customeradd.describe())\n",
    "#Caclulate missing data in columns\n",
    "print('\\n',customeradd.isnull().sum())\n",
    "print('\\n',customeradd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country  categories:  ['Australia']\n",
      "state  categories:  ['New South Wales' 'QLD' 'VIC' 'NSW' 'Victoria']\n"
     ]
    }
   ],
   "source": [
    "#Check Validity for category columns\n",
    "cat_columns = ['country', 'state']\n",
    "for category in cat_columns:\n",
    "    print(category,' categories: ',customeradd[category].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NSW', 'QLD', 'VIC'], dtype=object)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solve inValid/inConsistent data\n",
    "#use map to substitute 'New South Wales' to 'NSW', and 'Victoria' to 'VIC'\n",
    "mapping = {'New South Wales':'NSW', 'Victoria':'VIC', 'QLD':'QLD', 'NSW':'NSW', 'VIC':'VIC'}\n",
    "customeradd['state'] = customeradd['state'].map(mapping)\n",
    "customeradd['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [customer_id, address, postcode, state, country, property_valuation]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Check Uniqueness\n",
    "#Check keys customer_id for database\n",
    "print(customeradd[customeradd.customer_id.duplicated()==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of missing address info abt customers with ids:  [3, 10, 22, 23]\n",
      "list of extra address info abt customers with ids not present customerdemographics dataset:  [4001, 4002, 4003]\n",
      "[   1    2    4 ... 4001 4002 4003]\n"
     ]
    }
   ],
   "source": [
    "# Check Completness based on Uniqueness:\n",
    "#create empty lists to see what customer_id lacks in compare to customer_demographics dataset and vice versa:\n",
    "x=np.linspace(1,4000,4000).astype('int')\n",
    "custid = np.array(customeradd.customer_id.sort_values(ascending = True))\n",
    "missing_list = []\n",
    "extra_list = []\n",
    "\n",
    "#iterate over 4000 to check what is in customer_id and what are extra id's that cant be found in customer_demographics dataset\n",
    "for i in x:\n",
    "    if i not in custid:\n",
    "        missing_list.append(i)\n",
    "for i in custid:\n",
    "    if i not in x:\n",
    "        extra_list.append(i)\n",
    "\n",
    "print('list of missing address info abt customers with ids: ', missing_list)\n",
    "print('list of extra address info abt customers with ids not present customerdemographics dataset: ',extra_list)\n",
    "print(custid)\n",
    "\n",
    "#store final set to new variable\n",
    "customeradd_new = customeradd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3_2. Summary according to Data-Quality Dimensions:<br>\n",
    "        Accuracy:<br>\n",
    "            no issues<br>\n",
    "        Completeness:<br>\n",
    "            no missing data for given dataset, however cusomer_id lacks customer_id [3 10 22 23] and having extra ids [4001, 4002, 4003] can't be found in customer_demographics <br>\n",
    "        Consistency:<br>\n",
    "            no issues <br>\n",
    "        Currency:<br>\n",
    "            not applicable for current project<br>\n",
    "        Relevancy:<br>\n",
    "            no issues<br>\n",
    "        Validity:<br>\n",
    "            state: several notation for same state, was dealt with mapping to 3 letter notation <br>\n",
    "        Uniqueness:<br>\n",
    "            no issues in uniquenss, customeraddress base contains unique customer_id, however problems with completness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Summary and export final cleaned data back to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets summarize\n",
    "    #We have 3 datasets:\n",
    "        #transactions: have primary key which is transaction_id column and foreign key which is customer_id column\n",
    "        #customerdemo: have primary key which is customer_id column from 1 to 4000, total 4000 counts\n",
    "        #customeraddress: have primary key which is customer_id column from 1 to 4003 with some missing and extra id's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20310 \n",
      "        customer_id first_name  last_name  gender  \\\n",
      "0                1    Laraine  Medendorp  Female   \n",
      "1                1    Laraine  Medendorp  Female   \n",
      "2                1    Laraine  Medendorp  Female   \n",
      "3                1    Laraine  Medendorp  Female   \n",
      "4                1    Laraine  Medendorp  Female   \n",
      "...            ...        ...        ...     ...   \n",
      "20305         3999  Patrizius        NaN    Male   \n",
      "20306         4000      Kippy    Oldland    Male   \n",
      "20307         4001        NaN        NaN     NaN   \n",
      "20308         4002        NaN        NaN     NaN   \n",
      "20309         4003        NaN        NaN     NaN   \n",
      "\n",
      "       past_3_years_bike_related_purchases        DOB             job_title  \\\n",
      "0                                     93.0 1953-10-12   Executive Secretary   \n",
      "1                                     93.0 1953-10-12   Executive Secretary   \n",
      "2                                     93.0 1953-10-12   Executive Secretary   \n",
      "3                                     93.0 1953-10-12   Executive Secretary   \n",
      "4                                     93.0 1953-10-12   Executive Secretary   \n",
      "...                                    ...        ...                   ...   \n",
      "20305                                 11.0 1973-10-24                   NaN   \n",
      "20306                                 76.0 1991-11-05  Software Engineer IV   \n",
      "20307                                  NaN        NaT                   NaN   \n",
      "20308                                  NaN        NaT                   NaN   \n",
      "20309                                  NaN        NaT                   NaN   \n",
      "\n",
      "      job_industry_category     wealth_segment deceased_indicator  ...  \\\n",
      "0                    Health      Mass Customer                  N  ...   \n",
      "1                    Health      Mass Customer                  N  ...   \n",
      "2                    Health      Mass Customer                  N  ...   \n",
      "3                    Health      Mass Customer                  N  ...   \n",
      "4                    Health      Mass Customer                  N  ...   \n",
      "...                     ...                ...                ...  ...   \n",
      "20305         Manufacturing  Affluent Customer                  N  ...   \n",
      "20306                   NaN  Affluent Customer                  N  ...   \n",
      "20307                   NaN                NaN                NaN  ...   \n",
      "20308                   NaN                NaN                NaN  ...   \n",
      "20309                   NaN                NaN                NaN  ...   \n",
      "\n",
      "      transaction_date online_order  order_status           brand  \\\n",
      "0           2017-12-23          0.0      Approved      OHM Cycles   \n",
      "1           2017-04-06          1.0      Approved           Solex   \n",
      "2           2017-05-11          1.0      Approved   Trek Bicycles   \n",
      "3           2017-01-05          0.0      Approved  Norco Bicycles   \n",
      "4           2017-02-21          0.0      Approved           Solex   \n",
      "...                ...          ...           ...             ...   \n",
      "20305              NaT          NaN           NaN             NaN   \n",
      "20306              NaT          NaN           NaN             NaN   \n",
      "20307              NaT          NaN           NaN             NaN   \n",
      "20308              NaT          NaN           NaN             NaN   \n",
      "20309              NaT          NaN           NaN             NaN   \n",
      "\n",
      "       product_line product_class product_size  list_price  standard_cost  \\\n",
      "0          Standard        medium       medium      235.63         125.07   \n",
      "1          Standard        medium       medium     1577.53         826.51   \n",
      "2              Road           low        small     1720.70        1531.42   \n",
      "3          Standard        medium       medium      360.40         270.30   \n",
      "4          Standard        medium       medium       71.49          53.62   \n",
      "...             ...           ...          ...         ...            ...   \n",
      "20305           NaN           NaN          NaN         NaN            NaN   \n",
      "20306           NaN           NaN          NaN         NaN            NaN   \n",
      "20307           NaN           NaN          NaN         NaN            NaN   \n",
      "20308           NaN           NaN          NaN         NaN            NaN   \n",
      "20309           NaN           NaN          NaN         NaN            NaN   \n",
      "\n",
      "       product_first_sold_date  \n",
      "0                      38482.0  \n",
      "1                      39526.0  \n",
      "2                      37823.0  \n",
      "3                      37873.0  \n",
      "4                      38573.0  \n",
      "...                        ...  \n",
      "20305                      NaN  \n",
      "20306                      NaN  \n",
      "20307                      NaN  \n",
      "20308                      NaN  \n",
      "20309                      NaN  \n",
      "\n",
      "[20310 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# we can join 3 datasets, 2 (customeraddress & customerdemo) on outer join since we have some unoverlapping id's,\n",
    "combined_data = pd.merge(left = customerdemo_new, right = customeradd_new, left_on = 'customer_id', right_on = 'customer_id',how = 'outer')\n",
    "\n",
    "# and finally left join (customers_combined info on the left) on transactions, sutomers that did not order anything will be in database:\n",
    "combined_data = pd.merge(left = combined_data, right = transactions_new, left_on = 'customer_id', right_on = 'customer_id',how = 'left')\n",
    "print(len(combined_data),'\\n', combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('KPMG_new.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Write each dataframe to a different worksheet.\n",
    "transactions_new.to_excel(writer, sheet_name='transactions')\n",
    "customerdemo_new.to_excel(writer, sheet_name='customerdemographics')\n",
    "customeradd_new.to_excel(writer, sheet_name='customeraddress')\n",
    "combined_data.to_excel(writer, sheet_name='combined')\n",
    "\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
